### 日志管理

将机器上的日志实时收集，统一的存储到中心系统，并对日志信息建立索引，通过搜索快速找到对应的日志记录

ELK   ES +logstash+kibana

运维成本高，增加一个日志收集项目，需要手动修改配置



**kafka**  分布式数据流平台 

producer 生产者

kafka cluster kafka集群 

​					   broker ： 单个kafka实例

​						topic：消息的主题，可以理解为消息的分类，数据保存在topic中，每个broker可以创建多个topic

​						paritition：topic的分区，同一个topic可以有多个分区，来均衡负载，数据在分区内是不重复的

​						replication： 副本，主分区故障后，副本称为leader

consumer group：消费组，多个消费者组成消费者组，同一个分区的数据只能被组中某一个消费者消费，同一个消费者组的消费者可以消费同一个topic 不同分区的消息，提高了吞吐量



**生产者发往kafka的过程：**

1 生产者从集群中获知分区leader的信息

2 将消息发给leader leader将消息写入本地磁盘 

3 follwer从leader拉取消息数据

4 follwer将消息存盘 发送ack给leader

5 leader收到所有follwer的ack 向生产者发送ack



**选择partition的原则：**

指定pattition

hash 根据数据的key 计算出一个分区

轮询 每次写入一个 下次写入另一个



**ACK应答：参数设置 0 1 all**

0 不保证消息发送成功， 不用等待集群ack返回

1 只要leader 应答成功就发送下一条， 只确保leader接受成功

all  所有follower完成同步才发送下一条



**topic**

kafka针对每一个topci 维护了一个分区数据日志文件 每个partition都是有序且不可变的消息集合。



**kafka使用场景：**

消息队列

网站活动的追踪 实时计算实时监控

日志聚合



kafka和rabbitmq

kafka 常被用来大数据和日志数据等海量数据的处理，针对日志数据能够保证分区的顺序性，

但是rabbitmq不能保证顺序性，rabbitmq常被用来做订单和支付，rabbit更适合高并发的场景，使用erlang编写



logagent



etcd

**watch** 监控key的变化

watch是监听一个或一组key，key的任何变化都会发出消息。某种意义上讲，这就是发布订阅模式。

wathc中 重写了wtrie方法，任何写操作提交时，都会将本次change打包成event事件，发布到通道中，最后提交。



logtransfer



4. 